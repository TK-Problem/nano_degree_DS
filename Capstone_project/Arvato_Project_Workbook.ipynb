{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load in the data\n",
    "azdias = pd.read_csv('Udacity_AZDIAS_052018.csv', sep=';')\n",
    "customers = pd.read_csv('Udacity_CUSTOMERS_052018.csv', sep=';')\n",
    "\n",
    "# delete empty columns\n",
    "del azdias['Unnamed: 0']\n",
    "del customers['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>910215</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910220</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>910225</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910241</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  \\\n",
       "0  910215        -1         NaN       NaN          NaN          NaN   \n",
       "1  910220        -1         9.0       0.0          NaN          NaN   \n",
       "2  910225        -1         9.0      17.0          NaN          NaN   \n",
       "3  910226         2         1.0      13.0          NaN          NaN   \n",
       "4  910241        -1         1.0      20.0          NaN          NaN   \n",
       "\n",
       "   ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  \\\n",
       "0          NaN          NaN                   NaN                  NaN   \n",
       "1          NaN          NaN                  21.0                 11.0   \n",
       "2          NaN          NaN                  17.0                 10.0   \n",
       "3          NaN          NaN                  13.0                  1.0   \n",
       "4          NaN          NaN                  14.0                  3.0   \n",
       "\n",
       "          ...           VHN  VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  \\\n",
       "0         ...           NaN       NaN         NaN      NaN             NaN   \n",
       "1         ...           4.0       8.0        11.0     10.0             3.0   \n",
       "2         ...           2.0       9.0         9.0      6.0             3.0   \n",
       "3         ...           0.0       7.0        10.0     11.0             NaN   \n",
       "4         ...           2.0       3.0         5.0      4.0             2.0   \n",
       "\n",
       "   WOHNDAUER_2008  WOHNLAGE ZABEOTYP ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0             NaN       NaN        3         1                    2  \n",
       "1             9.0       4.0        5         2                    1  \n",
       "2             9.0       2.0        5         2                    3  \n",
       "3             9.0       7.0        3         2                    4  \n",
       "4             9.0       3.0        4         1                    3  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9626</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9628</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>SINGLE_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143872</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143873</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COSMETIC</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143874</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  \\\n",
       "0    9626         2         1.0      10.0          NaN          NaN   \n",
       "1    9628        -1         9.0      11.0          NaN          NaN   \n",
       "2  143872        -1         1.0       6.0          NaN          NaN   \n",
       "3  143873         1         1.0       8.0          NaN          NaN   \n",
       "4  143874        -1         1.0      20.0          NaN          NaN   \n",
       "\n",
       "   ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  \\\n",
       "0          NaN          NaN                  10.0                  1.0   \n",
       "1          NaN          NaN                   NaN                  NaN   \n",
       "2          NaN          NaN                   0.0                  1.0   \n",
       "3          NaN          NaN                   8.0                  0.0   \n",
       "4          NaN          NaN                  14.0                  7.0   \n",
       "\n",
       "          ...           VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  \\\n",
       "0         ...               2.0             6.0             9.0       7.0   \n",
       "1         ...               3.0             0.0             9.0       NaN   \n",
       "2         ...              11.0             6.0             9.0       2.0   \n",
       "3         ...               2.0             NaN             9.0       7.0   \n",
       "4         ...               4.0             2.0             9.0       3.0   \n",
       "\n",
       "   ZABEOTYP      PRODUCT_GROUP  CUSTOMER_GROUP ONLINE_PURCHASE ANREDE_KZ  \\\n",
       "0         3  COSMETIC_AND_FOOD     MULTI_BUYER               0         1   \n",
       "1         3               FOOD    SINGLE_BUYER               0         1   \n",
       "2         3  COSMETIC_AND_FOOD     MULTI_BUYER               0         2   \n",
       "3         1           COSMETIC     MULTI_BUYER               0         1   \n",
       "4         1               FOOD     MULTI_BUYER               0         1   \n",
       "\n",
       "  ALTERSKATEGORIE_GROB  \n",
       "0                    4  \n",
       "1                    4  \n",
       "2                    4  \n",
       "3                    4  \n",
       "4                    3  \n",
       "\n",
       "[5 rows x 369 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataFrame sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AZDIAS dataframe size\n",
      "rows: 891221\n",
      "cols: 366\n"
     ]
    }
   ],
   "source": [
    "print(\"AZDIAS dataframe size\\nrows: {}\\ncols: {}\".format(*azdias.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOMERS dataframe size\n",
      "rows: 191652\n",
      "cols: 369\n"
     ]
    }
   ],
   "source": [
    "print(\"CUSTOMERS dataframe size\\nrows: {}\\ncols: {}\".format(*customers.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Load DataFrame with information about all attributes\n",
    "\n",
    "1. read `DIAS Attributes - Values 2017.xlsx` file into pandas DataFrame,\n",
    "2. iterate over rows, read each attributes name, description and value meanings,\n",
    "3. read `DIAS Information Levels - Attributes 2017.xlsx` file into pandas DataFrame,\n",
    "4. join both DataFrames on Attribute and Description columns into one DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "      <th>Meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGER_TYP</td>\n",
       "      <td>best-ager typology</td>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>no classification possible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>passive elderly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>cultural elderly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>experience-driven elderly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attribute         Description Value                     Meaning\n",
       "0  AGER_TYP  best-ager typology    -1                     unknown\n",
       "1       NaN                 NaN     0  no classification possible\n",
       "2       NaN                 NaN     1             passive elderly\n",
       "3       NaN                 NaN     2            cultural elderly\n",
       "4       NaN                 NaN     3   experience-driven elderly"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. read `DIAS Attributes - Values 2017.xlsx` file into pandas DataFrame\n",
    "df_attr_1 = pd.read_excel('DIAS Attributes - Values 2017.xlsx')\n",
    "del df_attr_1['Unnamed: 0']\n",
    "df_attr_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Description</th>\n",
       "      <th>Values</th>\n",
       "      <th>Meanings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGER_TYP</td>\n",
       "      <td>best-ager typology</td>\n",
       "      <td>[-1, 0, 1, 2, 3]</td>\n",
       "      <td>[unknown, no classification possible, passive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERSKATEGORIE_GROB</td>\n",
       "      <td>age classification through prename analysis</td>\n",
       "      <td>[-1, 0, 1, 2, 3, 4, 9]</td>\n",
       "      <td>[unknown, &lt; 30 years, 30 - 45 years, 46 - 60 y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALTER_HH</td>\n",
       "      <td>main age within the household</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[unknown / no main age detectable, 01.01.1895 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANREDE_KZ</td>\n",
       "      <td>gender</td>\n",
       "      <td>[-1, 0, 1, 2]</td>\n",
       "      <td>[unknown, male, female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANZ_HAUSHALTE_AKTIV</td>\n",
       "      <td>number of households in the building</td>\n",
       "      <td>[…]</td>\n",
       "      <td>[numeric value (typically coded from 1-10)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Attribute                                   Description  \\\n",
       "0              AGER_TYP                            best-ager typology   \n",
       "1  ALTERSKATEGORIE_GROB  age classification through prename analysis    \n",
       "2              ALTER_HH                 main age within the household   \n",
       "3             ANREDE_KZ                                        gender   \n",
       "4   ANZ_HAUSHALTE_AKTIV          number of households in the building   \n",
       "\n",
       "                                              Values  \\\n",
       "0                                   [-1, 0, 1, 2, 3]   \n",
       "1                             [-1, 0, 1, 2, 3, 4, 9]   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3                                      [-1, 0, 1, 2]   \n",
       "4                                                […]   \n",
       "\n",
       "                                            Meanings  \n",
       "0  [unknown, no classification possible, passive ...  \n",
       "1  [unknown, < 30 years, 30 - 45 years, 46 - 60 y...  \n",
       "2  [unknown / no main age detectable, 01.01.1895 ...  \n",
       "3                            [unknown, male, female]  \n",
       "4        [numeric value (typically coded from 1-10)]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. iterate over rows, read each attributes name, description and value meanings,\n",
    "rows = list()\n",
    "start = False\n",
    "for idx in df_attr_1.index:\n",
    "    if df_attr_1.iloc[idx].Attribute is not np.nan:\n",
    "        if start:\n",
    "            rows.append([attribute, description, values, meanings])\n",
    "        # create lists to store Values and Meanings\n",
    "        values = list()\n",
    "        meanings = list()\n",
    "        # read data\n",
    "        attribute = df_attr_1.iloc[idx].Attribute\n",
    "        description = df_attr_1.iloc[idx].Description\n",
    "        # just quick and ungly way to skip saving first row\n",
    "        start = True\n",
    "        \n",
    "    # add values and meanings to the lists\n",
    "    values.append(df_attr_1.iloc[idx].Value)\n",
    "    meanings.append(df_attr_1.iloc[idx].Meaning)\n",
    "    \n",
    "rows.append([attribute, description, values, meanings])\n",
    "\n",
    "df_attr_1 = pd.DataFrame(rows, columns=[\"Attribute\", \"Description\", \"Values\", \"Meanings\"])\n",
    "df_attr_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Information level</th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Description</th>\n",
       "      <th>Additional notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AGER_TYP</td>\n",
       "      <td>best-ager typology</td>\n",
       "      <td>in cooperation with Kantar TNS; the informatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Person</td>\n",
       "      <td>ALTERSKATEGORIE_GROB</td>\n",
       "      <td>age through prename analysis</td>\n",
       "      <td>modelled on millions of first name-age-referen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ANREDE_KZ</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CJT_GESAMTTYP</td>\n",
       "      <td>Customer-Journey-Typology relating to the pref...</td>\n",
       "      <td>relating to the preferred information, marketi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>FINANZ_MINIMALIST</td>\n",
       "      <td>financial typology: low financial interest</td>\n",
       "      <td>Gfk-Typology based on a representative househo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Information level             Attribute  \\\n",
       "0               NaN              AGER_TYP   \n",
       "1            Person  ALTERSKATEGORIE_GROB   \n",
       "2               NaN             ANREDE_KZ   \n",
       "3               NaN         CJT_GESAMTTYP   \n",
       "4               NaN     FINANZ_MINIMALIST   \n",
       "\n",
       "                                         Description  \\\n",
       "0                                 best-ager typology   \n",
       "1                      age through prename analysis    \n",
       "2                                             gender   \n",
       "3  Customer-Journey-Typology relating to the pref...   \n",
       "4         financial typology: low financial interest   \n",
       "\n",
       "                                    Additional notes  \n",
       "0  in cooperation with Kantar TNS; the informatio...  \n",
       "1  modelled on millions of first name-age-referen...  \n",
       "2                                                NaN  \n",
       "3  relating to the preferred information, marketi...  \n",
       "4  Gfk-Typology based on a representative househo...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. read DIAS Information Levels - Attributes 2017.xlsx file into pandas DataFrame\n",
    "df_attr_2 = pd.read_excel('DIAS Information Levels - Attributes 2017.xlsx')\n",
    "del df_attr_2['Unnamed: 0']\n",
    "df_attr_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 attribute names which were written in inconvienient manner:\n",
    "\n",
    "* `D19_GESAMT_ANZ_12                                    D19_GESAMT_ANZ_24`,\n",
    "* `D19_BANKEN_ ANZ_12             D19_BANKEN_ ANZ_24`,\n",
    "* `D19_TELKO_ ANZ_12                  D19_TELKO_ ANZ_24`,\n",
    "* `D19_VERSI_ ANZ_12                                       D19_VERSI_ ANZ_24`,\n",
    "* `D19_VERSAND_ ANZ_12          D19_VERSAND_ ANZ_24`.\n",
    "\n",
    "These attributes will be manually fixed in cells bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Information level</th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Description</th>\n",
       "      <th>Additional notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_GESAMT_ANZ_12                             ...</td>\n",
       "      <td>transaction activity TOTAL POOL in the last 12...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_BANKEN_ ANZ_12             D19_BANKEN_ ANZ_24</td>\n",
       "      <td>transaction activity BANKS in the last 12 and ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_TELKO_ ANZ_12                  D19_TELKO_ ...</td>\n",
       "      <td>transaction activity TELCO in the last 12 and ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_VERSI_ ANZ_12                             ...</td>\n",
       "      <td>transaction activity INSURANCE in the last 12 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_VERSAND_ ANZ_12          D19_VERSAND_ ANZ_24</td>\n",
       "      <td>transaction activity MAIL-ORDER in the last 12...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Information level                                          Attribute  \\\n",
       "50               NaN  D19_GESAMT_ANZ_12                             ...   \n",
       "51               NaN  D19_BANKEN_ ANZ_12             D19_BANKEN_ ANZ_24   \n",
       "52               NaN  D19_TELKO_ ANZ_12                  D19_TELKO_ ...   \n",
       "53               NaN  D19_VERSI_ ANZ_12                             ...   \n",
       "54               NaN   D19_VERSAND_ ANZ_12          D19_VERSAND_ ANZ_24   \n",
       "\n",
       "                                          Description Additional notes  \n",
       "50  transaction activity TOTAL POOL in the last 12...              NaN  \n",
       "51  transaction activity BANKS in the last 12 and ...              NaN  \n",
       "52  transaction activity TELCO in the last 12 and ...              NaN  \n",
       "53  transaction activity INSURANCE in the last 12 ...              NaN  \n",
       "54  transaction activity MAIL-ORDER in the last 12...              NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_list = [\"D19_GESAMT_ANZ_12                                    D19_GESAMT_ANZ_24\",\n",
    "            \"D19_BANKEN_ ANZ_12             D19_BANKEN_ ANZ_24\",\n",
    "            \"D19_TELKO_ ANZ_12                  D19_TELKO_ ANZ_24\",\n",
    "            \"D19_VERSI_ ANZ_12                                       D19_VERSI_ ANZ_24\",\n",
    "            \"D19_VERSAND_ ANZ_12          D19_VERSAND_ ANZ_24\"]\n",
    "\n",
    "# get rows of attributes of interest into new DataFrame\n",
    "df_attr_3 = df_attr_2[df_attr_2.Attribute.isin(attr_list)]\n",
    "\n",
    "# remove those attribrutes from DataFrame \n",
    "df_attr_2 = df_attr_2[~df_attr_2.Attribute.isin(attr_list)]\n",
    "\n",
    "# check new DataFrame\n",
    "df_attr_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function which splits string into new strings was not an option because `D19_GESAMT_ANZ_12                                    D19_GESAMT_ANZ_24` would have two new strings `D19_GESAMT_ANZ_12` and `D19_GESAMT_ANZ_24`, but other attributes like `D19_BANKEN_ ANZ_12             D19_BANKEN_ ANZ_24` would result in 4 new strings `D19_BANKEN_`, `ANZ_12`, `D19_BANKEN_` and `ANZ_24`. Therefore I chose to just manualy iterate over rows and resave them into list->DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Information level</th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Description</th>\n",
       "      <th>Additional notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_GESAMT_ANZ_12</td>\n",
       "      <td>transaction activity TOTAL POOL in the last 12...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_GESAMT_ANZ_24</td>\n",
       "      <td>transaction activity TOTAL POOL in the last 24...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_BANKEN_ANZ_12</td>\n",
       "      <td>transaction activity BANKS in the last 12 months</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_BANKEN_ANZ_24</td>\n",
       "      <td>transaction activity BANKS in the last 24 months</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_TELKO_ANZ_12</td>\n",
       "      <td>transaction activity TELCO in the last 12 months</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_TELKO_ANZ_24</td>\n",
       "      <td>transaction activity TELCO in the last 24 months</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_VERSI_ANZ_12</td>\n",
       "      <td>transaction activity INSURANCE in the last 12 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_VERSI_ANZ_24</td>\n",
       "      <td>transaction activity INSURANCE in the last 24 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_VERSAND_ANZ_12</td>\n",
       "      <td>transaction activity MAIL-ORDER in the last 12...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D19_VERSAND_ANZ_24</td>\n",
       "      <td>transaction activity MAIL-ORDER in the last 24...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Information level           Attribute  \\\n",
       "0                NaN   D19_GESAMT_ANZ_12   \n",
       "1                NaN   D19_GESAMT_ANZ_24   \n",
       "2                NaN   D19_BANKEN_ANZ_12   \n",
       "3                NaN   D19_BANKEN_ANZ_24   \n",
       "4                NaN    D19_TELKO_ANZ_12   \n",
       "5                NaN    D19_TELKO_ANZ_24   \n",
       "6                NaN    D19_VERSI_ANZ_12   \n",
       "7                NaN    D19_VERSI_ANZ_24   \n",
       "8                NaN  D19_VERSAND_ANZ_12   \n",
       "9                NaN  D19_VERSAND_ANZ_24   \n",
       "\n",
       "                                         Description  Additional notes  \n",
       "0  transaction activity TOTAL POOL in the last 12...               NaN  \n",
       "1  transaction activity TOTAL POOL in the last 24...               NaN  \n",
       "2   transaction activity BANKS in the last 12 months               NaN  \n",
       "3   transaction activity BANKS in the last 24 months               NaN  \n",
       "4   transaction activity TELCO in the last 12 months               NaN  \n",
       "5   transaction activity TELCO in the last 24 months               NaN  \n",
       "6  transaction activity INSURANCE in the last 12 ...               NaN  \n",
       "7  transaction activity INSURANCE in the last 24 ...               NaN  \n",
       "8  transaction activity MAIL-ORDER in the last 12...               NaN  \n",
       "9  transaction activity MAIL-ORDER in the last 24...               NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temprarry list to store data\n",
    "_data = list()\n",
    "\n",
    "for idx in df_attr_3.index:\n",
    "    # split decription value with large space\n",
    "    attributes = df_attr_3.loc[idx].Attribute.split(\"          \")\n",
    "    # remove unneccesary spaces\n",
    "    attribute_12 = attributes[0].replace(\" \", \"\")\n",
    "    attribute_24 = attributes[-1].replace(\" \", \"\")\n",
    "    \n",
    "    # split decription value with \" and \"\n",
    "    description = df_attr_3.loc[idx].Description.split(\" and \")\n",
    "    # create new descriptions for 12 and 24 months\n",
    "    description_12 = description[0] + \" months\"\n",
    "    description_24 = description[0][:-2] + description[1]\n",
    "    \n",
    "    # add information about 12 month attribute\n",
    "    _data.append([np.nan, attribute_12, description_12, np.nan])\n",
    "    # add information about 24 month attribute\n",
    "    _data.append([np.nan, attribute_24, description_24, np.nan])\n",
    "    \n",
    "    \n",
    "# resave data into DataFrame\n",
    "df_attr_3 = pd.DataFrame(_data, columns=df_attr_3.columns)\n",
    "df_attr_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Description</th>\n",
       "      <th>Values</th>\n",
       "      <th>Meanings</th>\n",
       "      <th>Information level_x</th>\n",
       "      <th>Description_x</th>\n",
       "      <th>Additional notes_x</th>\n",
       "      <th>Information level_y</th>\n",
       "      <th>Description_y</th>\n",
       "      <th>Additional notes_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGER_TYP</td>\n",
       "      <td>best-ager typology</td>\n",
       "      <td>[-1, 0, 1, 2, 3]</td>\n",
       "      <td>[unknown, no classification possible, passive ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>best-ager typology</td>\n",
       "      <td>in cooperation with Kantar TNS; the informatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERSKATEGORIE_GROB</td>\n",
       "      <td>age classification through prename analysis</td>\n",
       "      <td>[-1, 0, 1, 2, 3, 4, 9]</td>\n",
       "      <td>[unknown, &lt; 30 years, 30 - 45 years, 46 - 60 y...</td>\n",
       "      <td>Person</td>\n",
       "      <td>age through prename analysis</td>\n",
       "      <td>modelled on millions of first name-age-referen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALTER_HH</td>\n",
       "      <td>main age within the household</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[unknown / no main age detectable, 01.01.1895 ...</td>\n",
       "      <td>Household</td>\n",
       "      <td>main age within the household</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANREDE_KZ</td>\n",
       "      <td>gender</td>\n",
       "      <td>[-1, 0, 1, 2]</td>\n",
       "      <td>[unknown, male, female]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANZ_HAUSHALTE_AKTIV</td>\n",
       "      <td>number of households in the building</td>\n",
       "      <td>[…]</td>\n",
       "      <td>[numeric value (typically coded from 1-10)]</td>\n",
       "      <td>Building</td>\n",
       "      <td>number of households known in this building</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Attribute                                   Description  \\\n",
       "0              AGER_TYP                            best-ager typology   \n",
       "1  ALTERSKATEGORIE_GROB  age classification through prename analysis    \n",
       "2              ALTER_HH                 main age within the household   \n",
       "3             ANREDE_KZ                                        gender   \n",
       "4   ANZ_HAUSHALTE_AKTIV          number of households in the building   \n",
       "\n",
       "                                              Values  \\\n",
       "0                                   [-1, 0, 1, 2, 3]   \n",
       "1                             [-1, 0, 1, 2, 3, 4, 9]   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3                                      [-1, 0, 1, 2]   \n",
       "4                                                […]   \n",
       "\n",
       "                                            Meanings Information level_x  \\\n",
       "0  [unknown, no classification possible, passive ...                 NaN   \n",
       "1  [unknown, < 30 years, 30 - 45 years, 46 - 60 y...              Person   \n",
       "2  [unknown / no main age detectable, 01.01.1895 ...           Household   \n",
       "3                            [unknown, male, female]                 NaN   \n",
       "4        [numeric value (typically coded from 1-10)]            Building   \n",
       "\n",
       "                                 Description_x  \\\n",
       "0                           best-ager typology   \n",
       "1                age through prename analysis    \n",
       "2                main age within the household   \n",
       "3                                       gender   \n",
       "4  number of households known in this building   \n",
       "\n",
       "                                  Additional notes_x  Information level_y  \\\n",
       "0  in cooperation with Kantar TNS; the informatio...                  NaN   \n",
       "1  modelled on millions of first name-age-referen...                  NaN   \n",
       "2                                                NaN                  NaN   \n",
       "3                                                NaN                  NaN   \n",
       "4                                                NaN                  NaN   \n",
       "\n",
       "  Description_y  Additional notes_y  \n",
       "0           NaN                 NaN  \n",
       "1           NaN                 NaN  \n",
       "2           NaN                 NaN  \n",
       "3           NaN                 NaN  \n",
       "4           NaN                 NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. join all DataFrames on Attribute and Description columns into one DataFrame.\n",
    "df_attr = pd.merge(df_attr_2, df_attr_3, on=['Attribute'], how='outer')\n",
    "df_attr = pd.merge(df_attr_1, df_attr, on=['Attribute'], how='outer')\n",
    "# rename Description_x columns\n",
    "# some descriptions for the same attribute differs in DataFrames, hence both descriptions are saved as separate columns\n",
    "# df_attr = df_attr.rename(columns={'Description_x': 'Description_a', 'Description_y': 'Description_i'})\n",
    "df_attr = df_attr.reset_index(drop=True)\n",
    "# del azdias['Description']\n",
    "df_attr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice**\n",
    "\n",
    "Using `pd.merge` created unneccesary columns `Information level_x`, `Information level_y`, `Additional notes_x` and ect., because some attributes had different descriptions in different `.xlsx` files. These columns only provide information for the human, So I didn't clean `df_attr` DataFrame more. For data processing  columns  columns were `Attribute`, `Values` and `Meanings` will only be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Attribute investigation\n",
    "\n",
    "One would expect that `df_attr` Attribute column should contain all column values from `azdias` and `customer` DataFrames. With closer investigation (cell bellow) we can see that it is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azdias DataFrame has 0 more attributes than customers DataFrame.\n",
      "customers DataFrame has 3 more attributes than azdias DataFrame.\n",
      "there are 90 column values in azdias DataFrame which are not found in df_attr Attribute column.\n",
      "there are 46 values in df_attr Attribute column which are not found among in azdias DataFrame columns.\n"
     ]
    }
   ],
   "source": [
    "A = set(azdias.columns)\n",
    "B = set(customers.columns)\n",
    "C = set(df_attr.Attribute) \n",
    "\n",
    "value_1 = A.difference(B)\n",
    "value_2 = B.difference(A)\n",
    "value_3 = A.difference(C)\n",
    "value_4 = C.difference(A)\n",
    "\n",
    "print(f\"azdias DataFrame has {len(value_1)} more attributes than customers DataFrame.\")\n",
    "print(f\"customers DataFrame has {len(value_2)} more attributes than azdias DataFrame.\")\n",
    "print(f\"there are {len(value_3)} column values in azdias DataFrame which are not found in df_attr Attribute column.\")\n",
    "print(f\"there are {len(value_4)} values in df_attr Attribute column which are not found among in azdias DataFrame columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a dictonary `attr_dict` which would rename `azdias` columns to match feature names in `attr` Attribute column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2.1 `D19_` attribute investigation\n",
    "\n",
    "Then I did manual investigation of features using following lines of code:\n",
    "\n",
    "```python\n",
    "for _ in value_3:\n",
    "    print(_)\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```python\n",
    "for _ in value_4:\n",
    "    print(_)\n",
    "```\n",
    "\n",
    "I found many features in boths sets starting with `D19_`. I decided to filter out these features in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sets for D19 features in azdias and attr DataFrames\n",
    "\n",
    "D19_azdias = set([_ for _ in value_3 if _[:4] == \"D19_\"])\n",
    "D19_attr = set([_ for _ in value_4 if _[:4] == \"D19_\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Some feature names in `attr` had `_RZ` endings. With simple loop these features were added to `attr_dict` dictonary, e.g.\n",
    "\n",
    "     `{'D19_ENERGIE': 'D19_ENERGIE_RZ'}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. rename D19 atributes which have `_RZ` ending \n",
    "for _ in D19_attr:\n",
    "    if _[:-3] in D19_azdias:\n",
    "        attr_dict[_[:-3]] = _\n",
    "\n",
    "# drop these attributes from the D19 sets\n",
    "D19_azdias = D19_azdias.difference(set(attr_dict.keys()))\n",
    "D19_attr = D19_attr.difference(set(attr_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Two `D19_` attributes ('D19_BUCH_CD' and 'D19_KONSUMTYP_MAX') were manually mapped (I assume there was a typo in one of the documents):\n",
    "\n",
    "    `{'D19_BUCH_CD': 'D19_BUCH_RZ', 'D19_KONSUMTYP_MAX': 'D19_KK_KUNDENTYP'}`\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. manually map two similiarly sounding attributes\n",
    "attr_dict['D19_BUCH_CD'] = 'D19_BUCH_RZ'\n",
    "attr_dict['D19_KONSUMTYP_MAX'] = 'D19_KK_KUNDENTYP'\n",
    "\n",
    "# drop these attributes from the D19 sets\n",
    "D19_azdias = D19_azdias.difference(set(['D19_BUCH_CD', 'D19_KONSUMTYP_MAX']))\n",
    "D19_attr = D19_attr.difference(set(['D19_BUCH_RZ', 'D19_KK_KUNDENTYP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D19_SOZIALES', 'D19_VERSI_ONLINE_QUOTE_12', 'D19_LETZTER_KAUF_BRANCHE', 'D19_TELKO_ONLINE_QUOTE_12'}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# check remaining D19 attributes\n",
    "print(D19_azdias)\n",
    "print(D19_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. With some keyword searching in `DIAS Attributes - Values 2017.xlsx` and `DIAS Information Levels - Attributes 2017.xlsx` files I suspect that columns `D19_TELKO_ONLINE_QUOTE_12` and `D19_VERSI_ONLINE_QUOTE_12` should mean **actuality of the last transaction for the segment telecommunication ONLINE within the last 12 months** and **transaction activity INSURANCE ONLINE in the last 12 months**, respectively. Numeric values should represent the procentage of online-transactions within the last 12 months as in other columns with `QUOTE_12` endings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  0., 10.,  7.,  5.,  9.,  3.,  8.,  6.,  4.,  2.,  1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of unique values with QUOTE_12 ending\n",
    "azdias[\"D19_VERSAND_ONLINE_QUOTE_12\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no Online-transactions within the last 12 months',\n",
       " '10% Online-transactions within the last 12 months',\n",
       " '20% Online-transactions within the last 12 months',\n",
       " '30% Online-transactions within the last 12 months',\n",
       " '40% Online-transactions within the last 12 months',\n",
       " '50% Online-transactions within the last 12 months',\n",
       " '60% Online-transactions within the last 12 months',\n",
       " '70% Online-transactions within the last 12 months',\n",
       " '80% Online-transactions within the last 12 months',\n",
       " '90% Online-transactions within the last 12 months',\n",
       " '100% Online-transactions within the last 12 months']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attr[df_attr.Attribute == \"D19_VERSAND_ONLINE_QUOTE_12\"]['Meanings'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  0., 10.,  5.,  7.,  3.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias[\"D19_TELKO_ONLINE_QUOTE_12\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  0., 10.,  5.,  7.,  8.,  6.,  3.,  9.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias[\"D19_VERSI_ONLINE_QUOTE_12\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. I tried searching `DIAS Attributes - Values 2017.xlsx` and `DIAS Information Levels - Attributes 2017.xlsx` files with key words `LETZTER`, `KAUF`, `BRANCHE` and `SOZIALES`, but nothing meaningful was found. Therefore I decided to drop `D19_LETZTER_KAUF_BRANCHE` and `D19_SOZIALES` features from `azdias` DataFrame (**letter in cell X**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D19_SOZIALES has 28.85 % missing values.\n",
      "D19_VERSI_ONLINE_QUOTE_12 has 28.85 % missing values.\n",
      "D19_LETZTER_KAUF_BRANCHE has 28.85 % missing values.\n",
      "D19_TELKO_ONLINE_QUOTE_12 has 28.85 % missing values.\n"
     ]
    }
   ],
   "source": [
    "for _ in D19_azdias:\n",
    "    nan_ratio = azdias[_].isna().sum()/azdias.shape[0]\n",
    "    print(f\"{_} has {nan_ratio*100:.2f} % missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D19_SOZIALES has 24.89 % missing values.\n",
      "D19_VERSI_ONLINE_QUOTE_12 has 24.89 % missing values.\n",
      "D19_LETZTER_KAUF_BRANCHE has 24.89 % missing values.\n",
      "D19_TELKO_ONLINE_QUOTE_12 has 24.89 % missing values.\n"
     ]
    }
   ],
   "source": [
    "for _ in D19_azdias:\n",
    "    nan_ratio = customers[_].isna().sum()/customers.shape[0]\n",
    "    print(f\"{_} has {nan_ratio*100:.2f} % missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From quick glance it seems that same users don't have information on these 4 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2.2 other attribute investigation\n",
    "\n",
    "Remaining attributes were investigated manualy by key-word searching `.xlxs` flies. Main remarks a listed here. Cells bellow only show arguments why some columns were renamed or removed.\n",
    "\n",
    "1) Attributes which are in found `DIAS Attributes - Values 2017.xlsx` and `DIAS Information Levels - Attributes 2017.xlsx` files, but are not present among `azdias` DataFrame columns.\n",
    "\n",
    "\n",
    "* **rename** `SOHO_FLAG` should be renamed with `SOHO_KZ`, there was probably a typo. For example, `TITEL_KZ` description is *flag whether this person holds an academic title*, similiar descriptions with word **flag** are for other attributes with `_KZ` endings, e.g.`OST_WEST_KZ`.\n",
    "\n",
    "\n",
    "* **rename** `CAMEO_DEUINTL_2015` should be renamed with `CAMEO_INTL_2015`. Column `CAMEO_INTL_2015` unique values are similiar to `CAMEO_DEUINTL_2015` values provided by `.xlsx` files.\n",
    "\n",
    "\n",
    "* **rename**  it seems that in `azdias` DataFrame column `KBA13_CCM_1401_2500` should be renamed to `KBA13_CCM_1400_2500`.\n",
    "\n",
    "\n",
    "* **remove** no meaningul comparisons were found for `EINWOHNER`, `GEOSCORE_KLS7`, `GKZ`, `PLZ`, `PLZ8` and `WACHSTUMSGEBIET_NB` attributes.\n",
    "\n",
    "\n",
    "* **remove** while `HAUSHALTSSTRUKTUR` sound similiar to `ANZ_STATISTISCHE_HAUSHALTE`, by closer inpection it was found that values differ a lot, `ANZ_STATISTISCHE_HAUSHALTE` contains numeric values >100, `HAUSHALTSSTRUKTUR` expects values in the range from -1 to 10.\n",
    "\n",
    "\n",
    "* **remove** `BIP_FLAG` could be either `DSL_FLAG`, `HH_DELTA_FLAG` and `UNGLEICHENN_FLAG`. Some additional clarification is needed, hence these attributes will be droped. \n",
    "\n",
    "\n",
    "2) Attributes which are present among `azdias` DataFrame columns, but not found in `.xlsx` files.\n",
    "\n",
    "\n",
    "* It seems that from `CJT_TYP_1` to `CJT_TYP_6` provides information about customer type. While this information is definetly important, these columsn ahd values from 1 to 5. If it was coded with 0s and 1s, indicating that client is TYP_1 or not TYP_1, then I would keep this data. For these reasons, I will drop all 6 columns.\n",
    "\n",
    "\n",
    "* Intuitively one might guess that columns `ALTER_KINDX` provide information about age type/kind. Unfortunetly, these columns are not binary, therefore it has more information than person belongs to age type 1. For these reasons, I will remove `ALTER_KINDX` columns.\n",
    "\n",
    "* Attributes with `KBA13_` prefix looks very simliar to attibutes with `KBA05_` prefix, e.g. `KBA13_ANTG1` and `KBA05_ALTER1`. On the other hand, descriptions of attributes with `KBA13_` prefix provide information about users with PLZ8 post code. One might think, that `KBA13_ANTG1` should be equivalent `PLZ8_ANTG1`. Unfortunetly, `azdias` DataFrame already contains columns `PLZ8_ANTG1`, which is different from `KBA13_ANTG1`.\n",
    "\n",
    "\n",
    "**Keeping columns in `azdias` DataFrame with unknow information, would complicating unsupervided learning result analys, e.g. you will find `CJT_TYP_1` being one of the pricipal components, but you will not be able to explain shareholders, what that information means. For this reason, columns, for wich I couldn;t find explanations in `.xlsx` files will be droped from `azdias` DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sets for NOT D19 features in azdias and attr DataFrames\n",
    "\n",
    "not_D19_azdias = set([_ for _ in value_3 if _[:4] != \"D19_\"])\n",
    "not_D19_attr = set([_ for _ in value_4 if _[:4] != \"D19_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AKT_DAT_KL',\n",
       " 'ALTERSKATEGORIE_FEIN',\n",
       " 'ALTER_KIND1',\n",
       " 'ALTER_KIND2',\n",
       " 'ALTER_KIND3',\n",
       " 'ALTER_KIND4',\n",
       " 'ANZ_KINDER',\n",
       " 'ANZ_STATISTISCHE_HAUSHALTE',\n",
       " 'CAMEO_INTL_2015',\n",
       " 'CJT_KATALOGNUTZER',\n",
       " 'CJT_TYP_1',\n",
       " 'CJT_TYP_2',\n",
       " 'CJT_TYP_3',\n",
       " 'CJT_TYP_4',\n",
       " 'CJT_TYP_5',\n",
       " 'CJT_TYP_6',\n",
       " 'DSL_FLAG',\n",
       " 'EINGEFUEGT_AM',\n",
       " 'EINGEZOGENAM_HH_JAHR',\n",
       " 'EXTSEL992',\n",
       " 'FIRMENDICHTE',\n",
       " 'GEMEINDETYP',\n",
       " 'HH_DELTA_FLAG',\n",
       " 'KBA13_ANTG1',\n",
       " 'KBA13_ANTG2',\n",
       " 'KBA13_ANTG3',\n",
       " 'KBA13_ANTG4',\n",
       " 'KBA13_BAUMAX',\n",
       " 'KBA13_CCM_1401_2500',\n",
       " 'KBA13_GBZ',\n",
       " 'KBA13_HHZ',\n",
       " 'KBA13_KMH_210',\n",
       " 'KK_KUNDENTYP',\n",
       " 'KOMBIALTER',\n",
       " 'KONSUMZELLE',\n",
       " 'LNR',\n",
       " 'MOBI_RASTER',\n",
       " 'RT_KEIN_ANREIZ',\n",
       " 'RT_SCHNAEPPCHEN',\n",
       " 'RT_UEBERGROESSE',\n",
       " 'SOHO_KZ',\n",
       " 'STRUKTURTYP',\n",
       " 'UMFELD_ALT',\n",
       " 'UMFELD_JUNG',\n",
       " 'UNGLEICHENN_FLAG',\n",
       " 'VERDICHTUNGSRAUM',\n",
       " 'VHA',\n",
       " 'VHN',\n",
       " 'VK_DHT4A',\n",
       " 'VK_DISTANZ',\n",
       " 'VK_ZG11'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_D19_azdias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BIP_FLAG',\n",
       " 'CAMEO_DEUINTL_2015',\n",
       " 'EINWOHNER',\n",
       " 'GEOSCORE_KLS7',\n",
       " 'GKZ',\n",
       " 'HAUSHALTSSTRUKTUR',\n",
       " 'KBA13_CCM_1400_2500',\n",
       " 'PLZ',\n",
       " 'PLZ8',\n",
       " 'SOHO_FLAG',\n",
       " 'WACHSTUMSGEBIET_NB'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_D19_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  2.,  3.,  1.,  4.,  0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias[\"PLZ8_ANTG1\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename `SOHO_KZ` with `SOHO_FLAG`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  1.,  0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias[\"SOHO_KZ\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306    [-1, 0, 1]\n",
       "Name: Values, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attr[df_attr.Attribute == \"SOHO_FLAG\"]['Values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unknown', 'no small office/home office', 'small office/home office']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attr[df_attr.Attribute == \"SOHO_FLAG\"]['Meanings'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306    small office/home office flag\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attr[df_attr.Attribute == \"SOHO_FLAG\"]['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add entry to rename dictonary\n",
    "attr_dict['SOHO_KZ'] = 'SOHO_FLAG'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename `CAMEO_INTL_2015` with `CAMEO_DEUINTL_2015`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 51.0, 24.0, 12.0, 43.0, 54.0, 22.0, 14.0, 13.0, 15.0, 33.0,\n",
       "       41.0, 34.0, 55.0, 25.0, 23.0, 31.0, 52.0, 35.0, 45.0, 44.0, 32.0,\n",
       "       '22', '24', '41', '12', '54', '51', '44', '35', '23', '25', '14',\n",
       "       '34', '52', '55', '31', '32', '15', '13', '43', '33', '45', 'XX'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias[\"CAMEO_INTL_2015\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([-1, 11, 12, 13, 14, 15, 21, 22, 23, 24, 25, 31, 32, 33, 34, 35, 41, 42, 43, 44, 45, 51, 52, 53, 54, 55])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attr[df_attr.Attribute == \"CAMEO_DEUINTL_2015\"]['Values'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CAMEO classification 2015 - international typology'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attr[df_attr.Attribute == \"CAMEO_DEUINTL_2015\"]['Description'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add entry to rename dictonary\n",
    "attr_dict['CAMEO_INTL_2015'] = 'CAMEO_DEUINTL_2015'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename `KBA13_CCM_1401_2500` with `KBA13_CCM_1400_2500`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_dict['KBA13_CCM_1401_2500'] = 'KBA13_CCM_1400_2500'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare `ANZ_STATISTISCHE_HAUSHALTE` with `HAUSHALTSSTRUKTUR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  12.,   7.,   2.,   3.,   5.,   6.,   1.,  14.,   4.,  11.,\n",
       "        13.,  30.,  22.,  36., 244.,  10.,  32.,   8.,   9.,  18.,  17.,\n",
       "        16.,  67.,  19.,  15.,  26.,  20.,  23.,  33.,  34.,  68.,  53.,\n",
       "        21.,  42.,  57.,  28.,  25.,  60.,  35.,  29.,  43.,  64.,  27.,\n",
       "        46.,  24.,  48.,  31.,  56.,  37., 243., 157.,  39.,  40.,  71.,\n",
       "        63.,  38.,  44.,  50., 101.,  66.,  41.,  81.,  47., 192., 131.,\n",
       "       149.,  74.,  84.,  80., 137.,  45.,  94.,  65.,  54.,  87.,  69.,\n",
       "       125.,  61.,  82.,  73.,  72.,  86., 292.,  70.,  83.,  91., 112.,\n",
       "        58.,  51.,  75.,  52.,  90., 140.,  49., 212.,  79., 152., 142.,\n",
       "       166., 251.,  99., 107.,  76., 173.,  89., 138.,  92., 154., 115.,\n",
       "       100.,  55., 116.,  88., 113., 162.,  95., 168.,  62.,  97., 110.,\n",
       "       127., 102.,  93., 103.,  78., 111., 114.,  77.,  98., 365., 146.,\n",
       "       109.,  59., 108., 289., 130.,  85., 119., 159., 183., 117., 303.,\n",
       "        96., 124., 163., 123., 122., 156., 155.,   0., 319., 104., 223.,\n",
       "       105., 128., 217., 129., 170., 218., 367., 253., 132., 328., 126.,\n",
       "       193., 133., 153., 118., 121., 233., 143., 229., 134., 256., 180.,\n",
       "       106., 202., 120., 136., 148., 204., 245., 135., 164., 248., 150.,\n",
       "       160., 147., 139., 189., 195., 187., 269., 179., 174., 161., 225.,\n",
       "       314., 158., 141., 167., 353., 354., 284., 258., 234., 194., 264.,\n",
       "       145., 239., 238., 144., 235., 369., 257., 227., 184., 296., 317.,\n",
       "       240., 213., 169., 199., 222., 230., 274., 181., 197., 237., 252.,\n",
       "       309., 339., 262., 366., 177., 241., 175., 304., 186., 178., 176.,\n",
       "       172., 200., 216., 182., 205., 228., 336., 445., 242., 299., 151.,\n",
       "       203., 185., 268., 214., 286., 322., 198., 449., 165., 190., 297.,\n",
       "       209., 342., 375., 371., 171.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias[\"ANZ_STATISTISCHE_HAUSHALTE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['-1, 0', 1, 2, 3, 4, 5, 6, 7, 8, 9])], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attr[df_attr.Attribute == \"HAUSHALTSSTRUKTUR\"]['Values'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate `CJT_TYP_X` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CJT_TYP_1\n",
      "[ 1.  5.  4.  2.  3. nan]\n",
      "\n",
      "CJT_TYP_2\n",
      "[ 1.  5.  4.  2.  3. nan]\n",
      "\n",
      "CJT_TYP_3\n",
      "[ 5.  2.  1.  4.  3. nan]\n",
      "\n",
      "CJT_TYP_4\n",
      "[ 5.  3.  4.  1.  2. nan]\n",
      "\n",
      "CJT_TYP_5\n",
      "[ 5.  1.  2.  3.  4. nan]\n",
      "\n",
      "CJT_TYP_6\n",
      "[ 5.  1.  2.  3.  4. nan]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1,7):\n",
    "    col_name = \"CJT_TYP_\" + str(_)\n",
    "    print(col_name)\n",
    "    print(azdias[col_name].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate `ALTER_KINDX` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALTER_KIND1\n",
      "[nan 17. 10. 18. 13. 16. 11.  6.  8.  9. 15. 14.  7. 12.  4.  3.  5.  2.]\n",
      "\n",
      "ALTER_KIND2\n",
      "[nan 13.  8. 12. 10.  7. 16. 15. 14. 17.  5.  9. 18. 11.  6.  4.  3.  2.]\n",
      "\n",
      "ALTER_KIND3\n",
      "[nan 10. 18. 17. 16.  8. 15.  9. 12. 13. 14. 11.  7.  5.  6.  4.]\n",
      "\n",
      "ALTER_KIND4\n",
      "[nan 10.  9. 16. 14. 13. 11. 18. 17. 15.  8. 12.  7.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1,5):\n",
    "    col_name = \"ALTER_KIND\" + str(_)\n",
    "    print(col_name)\n",
    "    print(azdias[col_name].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate `KBA13_XXXX` columns\n",
    "Values differ ine ach column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KBA13_ANTG1</th>\n",
       "      <th>PLZ8_ANTG1</th>\n",
       "      <th>KBA05_ALTER1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   KBA13_ANTG1  PLZ8_ANTG1  KBA05_ALTER1\n",
       "0          NaN         NaN           NaN\n",
       "1          2.0         2.0           3.0\n",
       "2          2.0         3.0           2.0\n",
       "3          2.0         2.0           2.0\n",
       "4          1.0         2.0           0.0\n",
       "5          2.0         2.0           0.0\n",
       "6          4.0         3.0           0.0\n",
       "7          2.0         3.0           1.0\n",
       "8          2.0         2.0           1.0\n",
       "9          2.0         2.0           2.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias[[\"KBA13_ANTG1\", \"PLZ8_ANTG1\", \"KBA05_ALTER1\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save `attr_dict` dictonary to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = [[key, val] for key, val in attr_dict.items()]\n",
    "pd.DataFrame(_data, columns=[\"Key\", \"Value\"]).to_csv(\"attribute_dict.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2.3 rename `azdias` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "azdias = azdias.rename(columns=attr_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Check for missing values\n",
    "\n",
    "In `df_attr` DataFrame `Meanings` column I found 3 key words indicating missing values: \"unknow\", \"none\" and \"nan\". Therefore, folowing procedure was done to create map for missing values:\n",
    "\n",
    "1. iterate over all `df_attr` rows,\n",
    "2. empty `nan_notations` list is created to save NAN value notations for spesific attribute,\n",
    "3. check if `Meanings` values is list. Proceed if True,\n",
    "4. iterate over all `Meanings` list elements,\n",
    "5. if element contains words \"unknown or none\" or is NAN object find notation values in `Values` column,\n",
    "6. notation could be either int or string, e.g. \"1, 9\". Function `convert_notation` converts notation into a list (it handles both cases),\n",
    "7. this list is then added to `nan_notations` list.\n",
    "8. after interation over rows is finished, new column `NAN_notations` with NAN value notations is added to `df_attr` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_notation(notation):\n",
    "    \"\"\"\n",
    "    Converts integer or string into list for NAN values notations.\n",
    "    \n",
    "    e.g.\n",
    "    \n",
    "    >>> convert_notation(\"1, 9\")\n",
    "    >>> [1, 9]\n",
    "    \n",
    "    >>> convert_notation(1)\n",
    "    >>> [1]\n",
    "    \n",
    "    Input:\n",
    "        notation: int or str\n",
    "    Output:\n",
    "        list\n",
    "    \"\"\"\n",
    "    if isinstance(notation, str):\n",
    "        return [int(_) for _ in notation.split(',')]\n",
    "    elif isinstance(notation, int):\n",
    "        return [notation]\n",
    "    else:\n",
    "        # create empty list to spot exceptions \n",
    "        print(\"converting notation failed:\")\n",
    "        print(notation)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temprarry list to store data\n",
    "_data = list()\n",
    "\n",
    "for idx in df_attr.index:\n",
    "    meanings = df_attr.loc[idx].Meanings\n",
    "    notations = df_attr.loc[idx].Values\n",
    "    # create empty list to store NAN value notations\n",
    "    nan_notations = list()\n",
    "    # check if meanings is list type. If true then iterrate over the lists\n",
    "    if isinstance(meanings, list):\n",
    "        for i in range(len(meanings)):\n",
    "            if meanings[i] is np.nan:\n",
    "                nan_notations += convert_notation(notations[i])\n",
    "            elif (\"unknown\" in meanings[i]) or ('none' in meanings[i]):\n",
    "                nan_notations += convert_notation(notations[i])\n",
    "                \n",
    "    # add NAN notations\n",
    "    _data.append(nan_notations)             \n",
    "            \n",
    "            \n",
    "# create new column with NAN values notations\n",
    "df_attr[\"NAN_notations\"] = pd.Series(_data)\n",
    "df_attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "\n",
    "A.difference(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.difference(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(B.difference(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.difference(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.difference(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"AGER_TYP\" in set(df_attr.Attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in df_attr.Attribute.values:\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# azdias.loc[:, _c[0]]\n",
    "df_attr[df_attr.Attribute == _c[0]]\n",
    "# loc[_c[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_nan(df, df_attr):\n",
    "    \"\"\"\n",
    "    Convert missing values to numpy NANs\n",
    "    \n",
    "    Input:\n",
    "        df: pandas DataFrame, \n",
    "        df_attr: pandas DataFrame,\n",
    "    Output:\n",
    "        df with NAN values \n",
    "    \"\"\"\n",
    "    for idx in feat_df.index:\n",
    "        # collumn name\n",
    "        col_n = feat_df.iloc[idx].attribute\n",
    "        # missing or unknow values for that collumn. Convert string to list\n",
    "        m_u = feat_df.iloc[idx].missing_or_unknown[1:-1].split(',')\n",
    "        # replace/convert values for those collumn/features, whose m_u value is empty list\n",
    "        if m_u != [\"\"]:\n",
    "            # convert values in the list to appropreate data type\n",
    "            # first get data dype of feture collum\n",
    "            # >> azdias[col_n].dtypes\n",
    "            # then convert list to np array\n",
    "            m_u = np.array(m_u, dtype=main_df[col_n].dtypes)\n",
    "            # replace any values in m_u array with np.nan\n",
    "            main_df[col_n] = main_df[col_n].replace(m_u, np.nan)\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to add in a lot more cells (both markdown and code) to document your\n",
    "# approach and findings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Segmentation Report\n",
    "\n",
    "The main bulk of your analysis will come in this part of the project. Here, you should use unsupervised learning techniques to describe the relationship between the demographics of the company's existing customers and the general population of Germany. By the end of this part, you should be able to describe parts of the general population that are more likely to be part of the mail-order company's main customer base, and which parts of the general population are less so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train.to_csv('Udacity_MAILOUT_052018_TRAIN.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter. If you're one of the top performers, you may have the chance to be contacted by a hiring manager from Arvato or Bertelsmann for an interview!\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer – this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TEST.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test.to_csv('Udacity_MAILOUT_052018_TEST.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
