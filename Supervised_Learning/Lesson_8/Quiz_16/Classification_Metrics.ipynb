{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Mission\n",
    "\n",
    "In this lesson you gained some insight into a number of techniques used to understand how well our model is performing.  This notebook is aimed at giving you some practice with the metrics specifically related to classification problems.  With that in mind, we will again be looking at the spam dataset from the earlier lessons.\n",
    "\n",
    "First, run the cell below to prepare the data and instantiate a number of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\PycharmProjects\\nano_degree_DS\\venv\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Import our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "import tests as t\n",
    "\n",
    "# Read in our dataset\n",
    "df = pd.read_table('SMSSpamCollection',\n",
    "                   sep='\\t', \n",
    "                   header=None, \n",
    "                   names=['label', 'sms_message'])\n",
    "\n",
    "# Fix our response value\n",
    "df['label'] = df.label.map({'ham':0, 'spam':1})\n",
    "\n",
    "# Split our dataset into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], \n",
    "                                                    df['label'], \n",
    "                                                    random_state=1)\n",
    "\n",
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# Fit the training data and then return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "\n",
    "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "testing_data = count_vector.transform(X_test)\n",
    "\n",
    "# Instantiate a number of our models\n",
    "naive_bayes = MultinomialNB()\n",
    "bag_mod = BaggingClassifier(n_estimators=200)\n",
    "rf_mod = RandomForestClassifier(n_estimators=200)\n",
    "ada_mod = AdaBoostClassifier(n_estimators=300, learning_rate=0.2)\n",
    "svm_mod = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 1**: Now, fit each of the above models to the appropriate data.  Answer the following question to assure that you fit the models correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n"
     ]
    }
   ],
   "source": [
    "# Fit each of the 4 models\n",
    "# This might take some time to run\n",
    "\n",
    "bag_mod.fit(training_data, y_train)\n",
    "rf_mod.fit(training_data, y_train)\n",
    "ada_mod.fit(training_data, y_train)\n",
    "svm_mod.fit(training_data, y_train)\n",
    "print('fit done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  You need to fit on both parts of the data pertaining to training data!\n"
     ]
    }
   ],
   "source": [
    "# The models you fit above were fit on which data?\n",
    "\n",
    "a = 'X_train'\n",
    "b = 'X_test'\n",
    "c = 'y_train'\n",
    "d = 'y_test'\n",
    "e = 'training_data'\n",
    "f = 'testing_data'\n",
    "\n",
    "# Change models_fit_on to only contain the correct string names\n",
    "# of values that you oassed to the above models\n",
    "\n",
    "models_fit_on = {e, c} # update this to only contain correct letters\n",
    "# don't have module t\n",
    "\n",
    "\n",
    "# Checks your solution - don't change this\n",
    "t.test_one(models_fit_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 2**: Now make predictions for each of your models on the data that will allow you to understand how well our model will extend to new data.  Then correctly add the strings to the set in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using each of your models\n",
    "bag_pred = bag_mod.predict(testing_data)\n",
    "rf_pred  = rf_mod.predict(testing_data)\n",
    "ada_pred = ada_mod.predict(testing_data)\n",
    "svm_pred = svm_mod.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right! To see how well our models perform in a new setting, you will want to predict on the test set of data.\n"
     ]
    }
   ],
   "source": [
    "# Which data was used in the predict method to see how well your\n",
    "# model would work on new data?\n",
    "\n",
    "a = 'X_train'\n",
    "b = 'X_test'\n",
    "c = 'y_train'\n",
    "d = 'y_test'\n",
    "e = 'training_data'\n",
    "f = 'testing_data'\n",
    "\n",
    "# Change models_predict_on to only contain the correct string names\n",
    "# of values that you oassed to the above models\n",
    "\n",
    "models_predict_on = { f} # update this to only contain correct letters\n",
    "# don't have module t\n",
    "\n",
    "# Checks your solution - don't change this\n",
    "t.test_two(models_predict_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have set up all your predictions, let's get to topis addressed in this lesson - measuring how well each of your models performed. First, we will focus on how each metric was calculated for a single model, and then in the final part of this notebook, you will choose models that are best based on a particular metric.\n",
    "\n",
    "You will be writing functions to calculate a number of metrics and then comparing the values to what you get from sklearn.  This will help you build intuition for how each metric is calculated.\n",
    "\n",
    "> **Step 3**: As an example of how this will work for the upcoming questions, run the cell below.  Fill in the below function to calculate accuracy, and then compare your answer to the built in to assure you are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "0.9763101220387652\n",
      "0.9763101220387652\n",
      "Since these match, we correctly calculated our metric!\n",
      "RandomForestClassifier\n",
      "0.9806173725771715\n",
      "0.9806173725771715\n",
      "Since these match, we correctly calculated our metric!\n",
      "AdaBoostClassifier\n",
      "0.9770279971284996\n",
      "0.9770279971284996\n",
      "Since these match, we correctly calculated our metric!\n",
      "SVC\n",
      "0.8671931083991385\n",
      "0.8671931083991385\n",
      "Since these match, we correctly calculated our metric!\n"
     ]
    }
   ],
   "source": [
    "# accuracy is the total correct divided by the total to predict\n",
    "def accuracy(actual, preds):\n",
    "    '''\n",
    "    INPUT\n",
    "    preds - predictions as a numpy array or pandas series\n",
    "    actual - actual values as a numpy array or pandas series\n",
    "    \n",
    "    OUTPUT:\n",
    "    returns the accuracy as a float\n",
    "    '''\n",
    "    return np.sum(preds == actual)/len(actual)\n",
    "\n",
    "print('BaggingClassifier')\n",
    "print(accuracy(y_test, bag_pred))\n",
    "print(accuracy_score(y_test, bag_pred))\n",
    "print(\"Since these match, we correctly calculated our metric!\")\n",
    "\n",
    "print('RandomForestClassifier')\n",
    "print(accuracy(y_test, rf_pred))\n",
    "print(accuracy_score(y_test, rf_pred))\n",
    "print(\"Since these match, we correctly calculated our metric!\")\n",
    "\n",
    "print('AdaBoostClassifier')\n",
    "print(accuracy(y_test, ada_pred))\n",
    "print(accuracy_score(y_test, ada_pred))\n",
    "print(\"Since these match, we correctly calculated our metric!\")\n",
    "\n",
    "print('SVC')\n",
    "print(accuracy(y_test, svm_pred))\n",
    "print(accuracy_score(y_test, svm_pred))\n",
    "print(\"Since these match, we correctly calculated our metric!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 4**: Fill in the below function to calculate precision, and then compare your answer to the built in to assure you are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "0.9222222222222223\n",
      "0.9222222222222223\n",
      "If the above match, you got it!\n",
      "RandomForestClassifier\n",
      "1.0\n",
      "1.0\n",
      "If the above match, you got it!\n",
      "AdaBoostClassifier\n",
      "0.9693251533742331\n",
      "0.9693251533742331\n",
      "If the above match, you got it!\n",
      "SVC\n",
      "0\n",
      "0.0\n",
      "If the above match, you got it!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\PycharmProjects\\nano_degree_DS\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# precision is the true positives over the predicted positive values\n",
    "def precision(actual, preds):\n",
    "    '''\n",
    "    INPUT\n",
    "    (assumes positive = 1 and negative = 0)\n",
    "    preds - predictions as a numpy array or pandas series \n",
    "    actual - actual values as a numpy array or pandas series\n",
    "    \n",
    "    OUTPUT:\n",
    "    returns the precision as a float\n",
    "    '''\n",
    "    \n",
    "    tp = len(np.intersect1d(np.where(preds==1), np.where(actual==1)))\n",
    "    pred_pos = (preds==1).sum()\n",
    "    if pred_pos > 0:\n",
    "        return tp/(pred_pos)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "print('BaggingClassifier')\n",
    "print(precision(y_test, bag_pred))\n",
    "print(precision_score(y_test, bag_pred))\n",
    "print(\"If the above match, you got it!\")\n",
    "\n",
    "print('RandomForestClassifier')\n",
    "print(precision(y_test, rf_pred))\n",
    "print(precision_score(y_test, rf_pred))\n",
    "print(\"If the above match, you got it!\")\n",
    "\n",
    "print('AdaBoostClassifier')\n",
    "print(precision(y_test, ada_pred))\n",
    "print(precision_score(y_test, ada_pred))\n",
    "print(\"If the above match, you got it!\")\n",
    "\n",
    "print('SVC')\n",
    "print(precision(y_test, svm_pred))\n",
    "print(precision_score(y_test, svm_pred))\n",
    "print(\"If the above match, you got it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 5**: Fill in the below function to calculate recall, and then compare your answer to the built in to assure you are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "0.8972972972972973\n",
      "0.8972972972972973\n",
      "If the above match, you got it!\n",
      "RandomForestClassifier\n",
      "0.8540540540540541\n",
      "0.8540540540540541\n",
      "If the above match, you got it!\n",
      "AdaBoostClassifier\n",
      "0.8540540540540541\n",
      "0.8540540540540541\n",
      "If the above match, you got it!\n",
      "SVC\n",
      "0.0\n",
      "0.0\n",
      "If the above match, you got it!\n"
     ]
    }
   ],
   "source": [
    "# recall is true positives over all actual positive values\n",
    "def recall(actual, preds):\n",
    "    '''\n",
    "    INPUT\n",
    "    preds - predictions as a numpy array or pandas series\n",
    "    actual - actual values as a numpy array or pandas series\n",
    "    \n",
    "    OUTPUT:\n",
    "    returns the recall as a float\n",
    "    '''\n",
    "\n",
    "    tp = len(np.intersect1d(np.where(preds==1), np.where(actual==1)))\n",
    "    act_pos = (actual==1).sum()\n",
    "    if act_pos > 0:\n",
    "        return tp/act_pos\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "print('BaggingClassifier')\n",
    "print(recall(y_test, bag_pred))\n",
    "print(recall_score(y_test, bag_pred))\n",
    "print(\"If the above match, you got it!\")\n",
    "\n",
    "print('RandomForestClassifier')\n",
    "print(recall(y_test, rf_pred))\n",
    "print(recall_score(y_test, rf_pred))\n",
    "print(\"If the above match, you got it!\")\n",
    "\n",
    "print('AdaBoostClassifier')\n",
    "print(recall(y_test, ada_pred))\n",
    "print(recall_score(y_test, ada_pred))\n",
    "print(\"If the above match, you got it!\")\n",
    "\n",
    "print('SVC')\n",
    "print(recall(y_test, svm_pred))\n",
    "print(recall_score(y_test, svm_pred))\n",
    "print(\"If the above match, you got it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 6**: Fill in the below function to calculate f1-score, and then compare your answer to the built in to assure you are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "0.9095890410958904\n",
      "0.9095890410958904\n",
      "If the above match, you got it!\n",
      "RandomForestClassifier\n",
      "0.9212827988338192\n",
      "0.9212827988338192\n",
      "If the above match, you got it!\n",
      "AdaBoostClassifier\n",
      "0.9080459770114943\n",
      "0.9080459770114943\n",
      "If the above match, you got it!\n",
      "SVC\n",
      "0\n",
      "0.0\n",
      "If the above match, you got it!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\PycharmProjects\\nano_degree_DS\\venv\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Tomas\\PycharmProjects\\nano_degree_DS\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# f1_score is 2*(precision*recall)/(precision+recall))\n",
    "def f1(preds, actual):\n",
    "    '''\n",
    "    INPUT\n",
    "    preds - predictions as a numpy array or pandas series\n",
    "    actual - actual values as a numpy array or pandas series\n",
    "    \n",
    "    OUTPUT:\n",
    "    returns the f1score as a float\n",
    "    '''\n",
    "    \n",
    "    tp = len(np.intersect1d(np.where(preds==1), np.where(actual==1)))\n",
    "    pred_pos = (preds==1).sum()\n",
    "    prec = tp/(pred_pos)\n",
    "    act_pos = (actual==1).sum()\n",
    "    recall = tp/act_pos\n",
    "    if (prec+recall) > 0:\n",
    "        return 2*(prec*recall)/(prec+recall)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "print('BaggingClassifier')\n",
    "print(f1(y_test, bag_pred))\n",
    "print(f1_score(y_test, bag_pred))\n",
    "print(\"If the above match, you got it!\")\n",
    "\n",
    "print('RandomForestClassifier')\n",
    "print(f1(y_test, rf_pred))\n",
    "print(f1_score(y_test, rf_pred))\n",
    "print(\"If the above match, you got it!\")\n",
    "\n",
    "print('AdaBoostClassifier')\n",
    "print(f1(y_test, ada_pred))\n",
    "print(f1_score(y_test, ada_pred))\n",
    "print(\"If the above match, you got it!\")\n",
    "\n",
    "print('SVC')\n",
    "print(f1(y_test, svm_pred))\n",
    "print(f1_score(y_test, svm_pred))\n",
    "print(\"If the above match, you got it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 7:** Now that you have calculated a number of different metrics, let's tie that to when we might use one versus another.  Use the dictionary below to match a metric to each statement that identifies when you would want to use that metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  It isn't really necessary to memorize these in practice, but it is important to know they exist and know why might use one metric over another for a particular situation.\n"
     ]
    }
   ],
   "source": [
    "# add the letter of the most appropriate metric to each statement\n",
    "# in the dictionary\n",
    "a = \"recall\"\n",
    "b = \"precision\"\n",
    "c = \"accuracy\"\n",
    "d = 'f1-score'\n",
    "\n",
    "\n",
    "seven_sol = {\n",
    "'We have imbalanced classes, which metric do we definitely not want to use?': c, # letter here,\n",
    "'We really want to make sure the positive cases are all caught even if that means we identify some negatives as positives': a, # letter here,    \n",
    "'When we identify something as positive, we want to be sure it is truly positive': b, # letter here, \n",
    "'We care equally about identifying positive and negative cases': d # letter here    \n",
    "}\n",
    "\n",
    "t.sol_seven(seven_sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 8:** Given what you know about the metrics now, use this information to correctly match the appropriate model to when it would be best to use each in the dictionary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  Naive Bayes was the best model for all of our metrics except precision!\n"
     ]
    }
   ],
   "source": [
    "# use the answers you found to the previous questiona, then match the model that did best for each metric\n",
    "a = \"naive-bayes\"\n",
    "b = \"bagging\"\n",
    "c = \"random-forest\"\n",
    "d = 'ada-boost'\n",
    "e = \"svm\"\n",
    "\n",
    "\n",
    "eight_sol = {\n",
    "'We have imbalanced classes, which metric do we definitely not want to use?': a, # letter here,\n",
    "'We really want to make sure the positive cases are all caught even if that means we identify some negatives as positives': a, # letter here,    \n",
    "'When we identify something as positive, we want to be sure it is truly positive': c, # letter here, \n",
    "'We care equally about identifying positive and negative cases': a # letter here  \n",
    "}\n",
    "\n",
    "t.sol_eight(eight_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells for work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get stuck, also notice there is a solution available by hitting the orange button in the top left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, preds, model_name=None):\n",
    "    '''\n",
    "    INPUT:\n",
    "    y_true - the y values that are actually true in the dataset (numpy array or pandas series)\n",
    "    preds - the predictions for those values from some model (numpy array or pandas series)\n",
    "    model_name - (str - optional) a name associated with the model if you would like to add it to the print statements \n",
    "    \n",
    "    OUTPUT:\n",
    "    None - prints the accuracy, precision, recall, and F1 score\n",
    "    '''\n",
    "    if model_name == None:\n",
    "        print('Accuracy score: ', format(accuracy_score(y_true, preds)))\n",
    "        print('Precision score: ', format(precision_score(y_true, preds)))\n",
    "        print('Recall score: ', format(recall_score(y_true, preds)))\n",
    "        print('F1 score: ', format(f1_score(y_true, preds)))\n",
    "        print('\\n\\n')\n",
    "    \n",
    "    else:\n",
    "        print('Accuracy score for ' + model_name + ' :' , format(accuracy_score(y_true, preds)))\n",
    "        print('Precision score ' + model_name + ' :', format(precision_score(y_true, preds)))\n",
    "        print('Recall score ' + model_name + ' :', format(recall_score(y_true, preds)))\n",
    "        print('F1 score ' + model_name + ' :', format(f1_score(y_true, preds)))\n",
    "        print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for bagging : 0.9763101220387652\n",
      "Precision score bagging : 0.9222222222222223\n",
      "Recall score bagging : 0.8972972972972973\n",
      "F1 score bagging : 0.9095890410958904\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for random forest : 0.9806173725771715\n",
      "Precision score random forest : 1.0\n",
      "Recall score random forest : 0.8540540540540541\n",
      "F1 score random forest : 0.9212827988338192\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for adaboost : 0.9770279971284996\n",
      "Precision score adaboost : 0.9693251533742331\n",
      "Recall score adaboost : 0.8540540540540541\n",
      "F1 score adaboost : 0.9080459770114943\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for svm : 0.8671931083991385\n",
      "Precision score svm : 0.0\n",
      "Recall score svm : 0.0\n",
      "F1 score svm : 0.0\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\PycharmProjects\\nano_degree_DS\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Tomas\\PycharmProjects\\nano_degree_DS\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Print Bagging scores\n",
    "print_metrics(y_test, bag_pred, 'bagging')\n",
    "\n",
    "# Print Random Forest scores\n",
    "print_metrics(y_test, rf_pred, 'random forest')\n",
    "\n",
    "# Print AdaBoost scores\n",
    "print_metrics(y_test, ada_pred, 'adaboost')\n",
    "\n",
    "# Naive Bayes Classifier scores\n",
    "# print_metrics(y_test, nb, 'naive bayes')\n",
    "\n",
    "# SVM Classifier scores\n",
    "print_metrics(y_test, svm_pred, 'svm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step in this workbook, let's take a look at the last three metrics you saw, f-beta scores, ROC curves, and AUC.\n",
    "\n",
    "**For f-beta scores:** If you decide that you care more about precision, you should move beta closer to 0.  If you decide you care more about recall, you should move beta towards infinity. \n",
    "\n",
    "> **Step 9:** Using the fbeta_score works similar to most of the other metrics in sklearn, but you also need to set beta as your weighting between precision and recall.  Use the space below to show that you can use [fbeta in sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html) to replicate your f1-score from above.  If in the future you want to use a different weighting, [this article](http://mlwiki.org/index.php/Precision_and_Recall) does an amazing job of explaining how you might adjust beta for different situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9095890410958904\n",
      "0.9095890410958904\n"
     ]
    }
   ],
   "source": [
    "#import fbeta score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "#show that the results are the same for fbeta and f1_score\n",
    "print(fbeta_score(y_test, bag_pred, beta=1))\n",
    "print(f1_score(y_test, bag_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 10:** Building ROC curves in python is a pretty involved process on your own.  I wrote the function below to assist with the process and make it easier for you to do so in the future as well.  Try it out using one of the other classifiers you created above to see how it compares to the random forest model below.\n",
    "\n",
    "Run the cell below to build a ROC curve, and retrieve the AUC for the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9432432432432433"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for calculating auc and roc\n",
    "\n",
    "def build_roc_auc(model, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    model - an sklearn instantiated model\n",
    "    X_train - the training data\n",
    "    y_train - the training response values (must be categorical)\n",
    "    X_test - the test data\n",
    "    y_test - the test response values (must be categorical)\n",
    "    OUTPUT:\n",
    "    auc - returns auc as a float\n",
    "    prints the roc curve\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from itertools import cycle\n",
    "    from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "    from scipy import interp\n",
    "    \n",
    "    y_preds = model.fit(X_train, y_train).predict_proba(X_test)\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(len(y_test)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test, y_preds[:, 1])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_preds[:, 1].ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "             lw=2, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc_score(y_test, np.round(y_preds[:, 1]))\n",
    "    \n",
    "    \n",
    "# Finding roc and auc for the random forest model    \n",
    "build_roc_auc(rf_mod, training_data, testing_data, y_train, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn here - choose another classifier to see how it compares\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
